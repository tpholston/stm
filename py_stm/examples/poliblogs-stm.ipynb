{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of STM in use\n",
    "This is different than poliblogs.ipynb because we are demonstrating use of metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrix\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from py_stm.stm import StmModel\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>docname</th>\n",
       "      <th>rating</th>\n",
       "      <th>day</th>\n",
       "      <th>blog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After a week of false statements, lies, and di...</td>\n",
       "      <td>at0800300_1.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I honestly don't know how either party's caucu...</td>\n",
       "      <td>at0800300_2.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While we stand in awe of the willingness of ou...</td>\n",
       "      <td>at0800300_3.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These pages recently said goodbye to global wa...</td>\n",
       "      <td>at0800300_4.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A US report shows how the enemy controlled the...</td>\n",
       "      <td>at0800300_5.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents           docname   \n",
       "0  After a week of false statements, lies, and di...  at0800300_1.text  \\\n",
       "1  I honestly don't know how either party's caucu...  at0800300_2.text   \n",
       "2  While we stand in awe of the willingness of ou...  at0800300_3.text   \n",
       "3  These pages recently said goodbye to global wa...  at0800300_4.text   \n",
       "4  A US report shows how the enemy controlled the...  at0800300_5.text   \n",
       "\n",
       "         rating  day blog  \n",
       "0  Conservative    3   at  \n",
       "1  Conservative    3   at  \n",
       "2  Conservative    3   at  \n",
       "3  Conservative    3   at  \n",
       "4  Conservative    3   at  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poliblogs = pd.read_csv(\"test_data/poliblogs2008.csv\", )\n",
    "poliblogs = poliblogs.loc[:, ~poliblogs.columns.str.contains('^Unnamed')]\n",
    "\n",
    "poliblogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13246 many documents in the poliblogs dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(poliblogs)} many documents in the poliblogs dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tyler\n",
      "[nltk_data]     Holston\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')  # Download the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, min_len):\n",
    "    tokens = simple_preprocess(text, deacc=True, min_len=min_len)  # deacc=True removes punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text and metadata for training\n",
    "train_text, test_text, train_metadata, test_metadata = train_test_split(\n",
    "    poliblogs.documents, poliblogs[['rating', 'day', 'blog']], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Apply the preprocessing function to the text data\n",
    "processed_train_text = [preprocess_text(text, min_len=3) for text in train_text]\n",
    "processed_test_text = [preprocess_text(text, min_len=3) for text in test_text]\n",
    "\n",
    "# Create the training dictionary\n",
    "dictionary = Dictionary(processed_train_text)\n",
    "\n",
    "# Filter extremes (remove tokens that appear in less than 10 documents, or more than 50% of the documents)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "\n",
    "# Create the training corpus (bag of words representation)\n",
    "corpus_train = [dictionary.doc2bow(text) for text in processed_train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A user could precompute the prevalence themselves like so\n",
    "from patsy import dmatrix\n",
    "\n",
    "prevalence = dmatrix(\"~rating+cr(day, df=3)\", data=train_metadata, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the STM model\n",
    "num_topics = 5  # Define the number of topics you want to extract\n",
    "stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, prevalence=prevalence, passes=2, random_state=420) # intended use 1. prevalence matrix precomputed\n",
    "stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, metadata=train_metadata, prevalence=\"~rating+cr(day, df=3)\", passes=2, random_state=420) # intended use 2. metadata dataframe with prevalence formula\n",
    "stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, metadata=train_metadata, content=\"~blog\", passes=2, random_state=420) # intended use 3. metadata dataframe and content formula"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
