{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of STM in use\n",
    "This is different than poliblogs.ipynb because we are demonstrating use of metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrix\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from py_stm.stm import StmModel\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>docname</th>\n",
       "      <th>rating</th>\n",
       "      <th>day</th>\n",
       "      <th>blog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After a week of false statements, lies, and di...</td>\n",
       "      <td>at0800300_1.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I honestly don't know how either party's caucu...</td>\n",
       "      <td>at0800300_2.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While we stand in awe of the willingness of ou...</td>\n",
       "      <td>at0800300_3.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These pages recently said goodbye to global wa...</td>\n",
       "      <td>at0800300_4.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A US report shows how the enemy controlled the...</td>\n",
       "      <td>at0800300_5.text</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents           docname   \n",
       "0  After a week of false statements, lies, and di...  at0800300_1.text  \\\n",
       "1  I honestly don't know how either party's caucu...  at0800300_2.text   \n",
       "2  While we stand in awe of the willingness of ou...  at0800300_3.text   \n",
       "3  These pages recently said goodbye to global wa...  at0800300_4.text   \n",
       "4  A US report shows how the enemy controlled the...  at0800300_5.text   \n",
       "\n",
       "         rating  day blog  \n",
       "0  Conservative    3   at  \n",
       "1  Conservative    3   at  \n",
       "2  Conservative    3   at  \n",
       "3  Conservative    3   at  \n",
       "4  Conservative    3   at  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poliblogs = pd.read_csv(\"test_data/poliblogs2008.csv\", )\n",
    "poliblogs = poliblogs.loc[:, ~poliblogs.columns.str.contains('^Unnamed')]\n",
    "\n",
    "poliblogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13246 many documents in the poliblogs dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(poliblogs)} many documents in the poliblogs dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tyler\n",
      "[nltk_data]     Holston\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')  # Download the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, min_len):\n",
    "    tokens = simple_preprocess(text, deacc=True, min_len=min_len)  # deacc=True removes punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text and metadata for training\n",
    "train_text, test_text, train_metadata, test_metadata = train_test_split(\n",
    "    poliblogs.documents, poliblogs[['rating', 'day', 'blog']], test_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "# Apply the preprocessing function to the text data\n",
    "processed_train_text = [preprocess_text(text, min_len=3) for text in train_text]\n",
    "processed_test_text = [preprocess_text(text, min_len=3) for text in test_text]\n",
    "\n",
    "# Create the training dictionary\n",
    "dictionary = Dictionary(processed_train_text)\n",
    "\n",
    "# Filter extremes (remove tokens that appear in less than 10 documents, or more than 50% of the documents)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "\n",
    "# Create the training corpus (bag of words representation)\n",
    "corpus_train = [dictionary.doc2bow(text) for text in processed_train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.46802029e-04, 2.93869088e-04, 7.97644667e-04, ...,\n",
       "       2.00780122e-05, 2.19032860e-05, 2.55538337e-05])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "corpus_train[190]\n",
    "doc_idx, word_idx, count = [], [], []\n",
    "\n",
    "for i, doc in enumerate(corpus_train):\n",
    "\tfor word, freq in doc:\n",
    "\t\tdoc_idx.append(i)\n",
    "\t\tword_idx.append(word)\n",
    "\t\tcount.append(freq)\n",
    "\n",
    "a = csr_matrix((count, (doc_idx, word_idx)))\n",
    "\n",
    "wprob = np.sum(a, axis=0)\n",
    "wprob = wprob / np.sum(wprob)    \n",
    "wprob = np.array(wprob)\n",
    "\n",
    "wprob.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>rating[T.Liberal]</th>\n",
       "      <th>cr(day, df=3)[0]</th>\n",
       "      <th>cr(day, df=3)[1]</th>\n",
       "      <th>cr(day, df=3)[2]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>-0.070993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.096484</td>\n",
       "      <td>0.804462</td>\n",
       "      <td>0.292022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027219</td>\n",
       "      <td>0.163578</td>\n",
       "      <td>0.863640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.096609</td>\n",
       "      <td>0.739139</td>\n",
       "      <td>0.357470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558841</td>\n",
       "      <td>0.519251</td>\n",
       "      <td>-0.078092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.175061</td>\n",
       "      <td>0.907666</td>\n",
       "      <td>-0.082727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863043</td>\n",
       "      <td>0.163875</td>\n",
       "      <td>-0.026919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>-0.070993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310744</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>-0.095325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077823</td>\n",
       "      <td>0.931178</td>\n",
       "      <td>0.146646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2649 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Intercept  rating[T.Liberal]  cr(day, df=3)[0]  cr(day, df=3)[1]   \n",
       "11708        1.0                1.0          0.609936          0.461057  \\\n",
       "7650         1.0                0.0         -0.096484          0.804462   \n",
       "8599         1.0                0.0         -0.027219          0.163578   \n",
       "7788         1.0                0.0         -0.096609          0.739139   \n",
       "3456         1.0                1.0          0.558841          0.519251   \n",
       "...          ...                ...               ...               ...   \n",
       "11964        1.0                1.0          0.175061          0.907666   \n",
       "5191         1.0                0.0          0.863043          0.163875   \n",
       "5390         1.0                0.0          0.609936          0.461057   \n",
       "860          1.0                0.0          0.310744          0.784581   \n",
       "7270         1.0                0.0         -0.077823          0.931178   \n",
       "\n",
       "       cr(day, df=3)[2]  \n",
       "11708         -0.070993  \n",
       "7650           0.292022  \n",
       "8599           0.863640  \n",
       "7788           0.357470  \n",
       "3456          -0.078092  \n",
       "...                 ...  \n",
       "11964         -0.082727  \n",
       "5191          -0.026919  \n",
       "5390          -0.070993  \n",
       "860           -0.095325  \n",
       "7270           0.146646  \n",
       "\n",
       "[2649 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A user could precompute the prevalence themselves like so\n",
    "from patsy import dmatrix\n",
    "\n",
    "# prevalence = dmatrix(\"~rating+cr(day, df=3)\", data=train_metadata, return_type='dataframe')\n",
    "prevalence = dmatrix(\"~rating+cr(day, df=3)\", data=train_metadata, return_type='dataframe')\n",
    "a = prevalence.astype(\"category\")\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tyler Holston\\OneDrive\\Desktop\\AssortedPythonStuff\\stm\\env\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "WARNING:py_stm.stm:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "# Train the STM model\n",
    "num_topics = 5  # Define the number of topics you want to extract\n",
    "\n",
    "# PREVALENCE MODEL\n",
    "#stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, prevalence=prevalence, passes=2, random_state=420) # intended use 1. prevalence matrix precomputed\n",
    "#stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, metadata=train_metadata, prevalence=\"~rating+cr(day, df=3)\", passes=2, random_state=420) # intended use 2. metadata dataframe with prevalence formula\n",
    "\n",
    "# CONTENT MODEL\n",
    "#stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, metadata=train_metadata, content=train_metadata.loc[:, \"rating\"], passes=2, random_state=420) # intended use 3. metadata dataframe and content formula\n",
    "\n",
    "# BOTH MODEL\n",
    "stm = StmModel(corpus_train, num_topics=num_topics, id2word=dictionary, prevalence=prevalence, content=train_metadata.loc[:, \"rating\"], passes=2, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Words:\n",
      "Topic 0: mccain, john, said, palin, think, today, new, sen, even, campaign, going, people, like, war, time\n",
      "Topic 1: bush, iraq, administration, house, war, government, mccain, said, security, new, people, president, like, white, time\n",
      "Topic 2: president, said, people, like, american, new, time, think, government, years, right, know, war, also, even\n",
      "Topic 3: campaign, said, new, people, like, barack, time, get, also, know, last, american, palin, even, political\n",
      "Topic 4: hillary, clinton, even, could, like, new, state, people, two, democrats, time, think, get, may, vote\n",
      "\n",
      "Covariate Words:\n",
      "Group Liberal: mccain, like, new, people, even, said, time, two, campaign, barack, get, may, last, government, could\n",
      "Group Conservative: said, mccain, new, people, president, bush, campaign, think, like, john, iraq, know, right, time, today\n",
      "\n",
      "Topic-Covariate Interactions:\n",
      "Topic 0, Group Liberal: mccain, john, even, said, palin, new, two, update, like, people, may, time, also, barack, last \n",
      "Topic 0, Group Conservative: mccain, john, said, sen, think, today, palin, new, going, campaign, president, know, right, war, people \n",
      "Topic 1, Group Liberal: bush, iraq, government, war, mccain, administration, house, even, like, new, people, two, last, may, time \n",
      "Topic 1, Group Conservative: bush, iraq, administration, house, war, mccain, security, said, government, white, president, new, people, today, think \n",
      "Topic 2, Group Liberal: president, said, people, like, government, american, new, years, even, time, also, may, get, last, two \n",
      "Topic 2, Group Conservative: president, said, people, think, new, like, american, know, right, time, war, years, today, country, going \n",
      "Topic 3, Group Liberal: campaign, new, barack, said, like, people, get, time, last, even, political, two, also, times, well \n",
      "Topic 3, Group Conservative: campaign, said, new, people, like, know, time, going, right, today, get, barack, also, american, palin \n",
      "Topic 4, Group Liberal: hillary, clinton, even, democrats, two, could, may, state, like, time, vote, get, last, barack, new \n",
      "Topic 4, Group Conservative: hillary, think, clinton, new, people, like, time, state, could, democratic, even, get, right, going, today \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([['mccain', 'john', 'said', 'palin', 'think', 'today', 'new',\n",
       "         'sen', 'even', 'campaign', 'going', 'people', 'like', 'war',\n",
       "         'time'],\n",
       "        ['bush', 'iraq', 'administration', 'house', 'war', 'government',\n",
       "         'mccain', 'said', 'security', 'new', 'people', 'president',\n",
       "         'like', 'white', 'time'],\n",
       "        ['president', 'said', 'people', 'like', 'american', 'new', 'time',\n",
       "         'think', 'government', 'years', 'right', 'know', 'war', 'also',\n",
       "         'even'],\n",
       "        ['campaign', 'said', 'new', 'people', 'like', 'barack', 'time',\n",
       "         'get', 'also', 'know', 'last', 'american', 'palin', 'even',\n",
       "         'political'],\n",
       "        ['hillary', 'clinton', 'even', 'could', 'like', 'new', 'state',\n",
       "         'people', 'two', 'democrats', 'time', 'think', 'get', 'may',\n",
       "         'vote']], dtype='<U14'),\n",
       " array([['mccain', 'like', 'new', 'people', 'even', 'said', 'time', 'two',\n",
       "         'campaign', 'barack', 'get', 'may', 'last', 'government',\n",
       "         'could'],\n",
       "        ['said', 'mccain', 'new', 'people', 'president', 'bush',\n",
       "         'campaign', 'think', 'like', 'john', 'iraq', 'know', 'right',\n",
       "         'time', 'today']], dtype='<U14'),\n",
       " array([['mccain', 'john', 'even', 'said', 'palin', 'new', 'two',\n",
       "         'update', 'like', 'people', 'may', 'time', 'also', 'barack',\n",
       "         'last'],\n",
       "        ['bush', 'iraq', 'government', 'war', 'mccain', 'administration',\n",
       "         'house', 'even', 'like', 'new', 'people', 'two', 'last', 'may',\n",
       "         'time'],\n",
       "        ['president', 'said', 'people', 'like', 'government', 'american',\n",
       "         'new', 'years', 'even', 'time', 'also', 'may', 'get', 'last',\n",
       "         'two'],\n",
       "        ['campaign', 'new', 'barack', 'said', 'like', 'people', 'get',\n",
       "         'time', 'last', 'even', 'political', 'two', 'also', 'times',\n",
       "         'well'],\n",
       "        ['hillary', 'clinton', 'even', 'democrats', 'two', 'could', 'may',\n",
       "         'state', 'like', 'time', 'vote', 'get', 'last', 'barack', 'new'],\n",
       "        ['mccain', 'john', 'said', 'sen', 'think', 'today', 'palin',\n",
       "         'new', 'going', 'campaign', 'president', 'know', 'right', 'war',\n",
       "         'people'],\n",
       "        ['bush', 'iraq', 'administration', 'house', 'war', 'mccain',\n",
       "         'security', 'said', 'government', 'white', 'president', 'new',\n",
       "         'people', 'today', 'think'],\n",
       "        ['president', 'said', 'people', 'think', 'new', 'like',\n",
       "         'american', 'know', 'right', 'time', 'war', 'years', 'today',\n",
       "         'country', 'going'],\n",
       "        ['campaign', 'said', 'new', 'people', 'like', 'know', 'time',\n",
       "         'going', 'right', 'today', 'get', 'barack', 'also', 'american',\n",
       "         'palin'],\n",
       "        ['hillary', 'think', 'clinton', 'new', 'people', 'like', 'time',\n",
       "         'state', 'could', 'democratic', 'even', 'get', 'right', 'going',\n",
       "         'today']], dtype='<U14'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm.label_topics(range(0,5), n=15, print_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 2\n",
      "2310    At NationalPost.com, journalist David Frum has...\n",
      "1811    On July 12th of this year, just two and a half...\n",
      "682     Thanks to the release of Barack Obama's income...\n",
      "1375    AT contributors have some further thoughts on ...\n",
      "2465    What is it with the legacy media? Don't they k...\n",
      "Name: documents, dtype: object\n",
      "\n",
      "\n",
      "Topic: 3\n",
      "2579    Last Sunday, when Joe Biden predicted that a P...\n",
      "2410    ACORN, responsible for so much vote fraud in W...\n",
      "219     Defying the expectations of the pundits, John ...\n",
      "1487    You have to wonder what will be going through ...\n",
      "1247    Making it clear that she will not allow any co...\n",
      "Name: documents, dtype: object\n",
      "\n",
      "\n",
      "Topic: 4\n",
      "1230    Note to Iran apologists: Even the United Natio...\n",
      "1959    Last week, Ukrainian President Viktor Yushchen...\n",
      "115     Continuing his visit to the Middle East, Presi...\n",
      "861     With distorted glasses on his eyes and hatred ...\n",
      "1623    How do journalism schools manage to keep train...\n",
      "Name: documents, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stm.N = stm.lencorpus\n",
    "topics = [2, 3, 4] # or range(2, 5)\n",
    "for topic, docs in zip(topics, stm.find_thoughts(topics, n=6)):\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(poliblogs.iloc[docs]['documents'])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
